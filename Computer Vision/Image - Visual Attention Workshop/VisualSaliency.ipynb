{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VisualSaliency.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-TBE56W8Cpf"
      },
      "source": [
        "## **Future Data Hackers**\n",
        "# **Session 4 - Salient Object Detection: Guessing the viewers’ favourite objects in visual science**\n",
        "\n",
        "**Publisher:** University of Bradford (https://www.bradford.ac.uk/ei/computer-science/)\n",
        "\n",
        "**Developer**: Dr. Irfan Mehmood  (https://www.bradford.ac.uk/staff/imehmood4)\n",
        "\n",
        "**Contact Info**: i.mehmood4@bradford.ac.uk\n",
        "\n",
        "**Salient Object Detection is** a very important aspect of any object detection system because it saves a lot of unnecessary computation time. It helps to locate where an object of interest can be found in an image. All the object detection systems, first figure out where they have to look for an object in an image, based on **saliency**. Then, they classify whether the specified attention gained area is the same object which you are looking for. In this session, we will explore how the region of interests can be figured out through visual Saliency. \n",
        "\n",
        "**Visual Saliency:** Human brain responds to the visual world via a collection of parallel neural pathways beginning in the retina. Some of these pathways perform selective modulation of the visual signal, highlighting features and locations that contain relevant information. Because we can only look at one location at a time, such selectivity allows us to sequentially sample the visual world by visual saliency modelling. \n",
        "\n",
        "**Visual Saliency Examples**\n",
        "\n",
        "- https://drive.google.com/file/d/1193PaCJMeGoMdb_s0zxCve-pP2f-HPBT/view?usp=sharing\n",
        "- https://drive.google.com/file/d/1uYet0aQKUWs6b4WFZTI_uOPMQPrHZUuH/view?usp=sharing\n",
        "\n",
        "**Aim:** Explore what is saliency and its role in **computer vision**. \n",
        "\n",
        "**Objectives**\n",
        "- To explore various visual saliencies libraries and methods available in python \n",
        "- To understand the applications of saliency in brain MRI analysis and visual surveillance\n",
        "- To highlight the existing challenges with visual saliency \n",
        "\n",
        "**Outline**\n",
        "\n",
        "1. Introdcution to computer vision\n",
        "2. Visual attention and visual saliency \n",
        "3. Applications of visual saliency \n",
        "4. Challenges in saliency computation\n",
        "5. Visual saliency example codes\n",
        "6. Summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg-7vcdhF9pL"
      },
      "source": [
        "# **1   Computer Vision**\n",
        "- Computer vision is a field of artificial intelligence (AI).\n",
        "- It enables computers and systems to derive meaningful information from digital images, videos and other visual inputs — and take actions or make recommendations based on that information. \n",
        "- AI enables computers to think, computer vision enables machines to see, observe and understand.\n",
        "\n",
        "\n",
        "Here are a few examples of established computer vision tasks:\n",
        "- Image classification \n",
        "- Object detection \n",
        "- Object tracking \n",
        "- Content-based image retrieval\n",
        "\n",
        "Example - https://drive.google.com/file/d/1ncOLc6e-zun8ini91PR9Oc2XbQYqk93j/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XP1fxh83xjD"
      },
      "source": [
        "# **2   Visual Attention and Visual Saliency**\n",
        "\n",
        "**Visual attention** is the selection process in human vision which directs the gaze to the currently most interesting data.\n",
        "\n",
        "These salient regions might:\n",
        "\n",
        "- \"pop out\" of the image automatically. This is example of **bottom-up** salient region detection.\n",
        "\n",
        "- cues which are of current interest due to pre-knowledge about the target object or the scene called **top-down** approach.\n",
        "\n",
        "  Top-down vs botton-up approach:\n",
        "\n",
        "  https://drive.google.com/file/d/113hXw_RfOgBbTzQNdSCW5XLfUOgJs3Jk/view?usp=sharing\n",
        "  https://drive.google.com/file/d/12PIDIWwoVuNfBMW9zmGVpnPJFUIhcng7/view?usp=sharing\n",
        "\n",
        "**Visual saliency** is the distinct subjective perceptual quality which makes some items in the world stand out from their neighbours and immediately grab our attention. \n",
        "\n",
        "Visual saliency or saliency maps are the output of visual attention. \n",
        "\n",
        "**Types of Saliencies**:\n",
        "- Static Saliency: In this category of algorithms the salient region is detected on a single frame based on different image features such as a change, in contrast, intensity and pattern.\n",
        "- Motion Saliency: In this category of algorithms the salient object is detected on videos/ moving frames based on the change in features between subsequent frames.\n",
        "\n",
        "  Example of Static vs motion saliency\n",
        "  https://drive.google.com/file/d/1j1VIe8IKVhOYkqTJdK_TP7HcNndu8oNY/view?usp=sharing\n",
        "\n",
        "\n",
        "**Applications**:\n",
        "The saliency detection technique is widely used in the fields of computer vision like:\n",
        "- Target detection and cognition\n",
        "- Image retrieval\n",
        "- Object discovery\n",
        "- Image segmentation\n",
        "- Video summarization and skimming\n",
        "- Image and video compression\n",
        "- Image automation pruning\n",
        "- Visual tracking\n",
        "\n",
        "**Goal**\n",
        "\n",
        "- A saliency map is an image that shows each pixel's unique quality. \n",
        "- The goal of a saliency map is to simplify and/or change the representation of an image into something that is more meaningful and easier to analyse for different computer vision tasks.\n",
        "\n",
        "Example - https://drive.google.com/file/d/1cDoQh4x5GoLvX3WIXhUdL5IVE_4wim1L/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIg6mfescpGU"
      },
      "source": [
        "# **3   Applications of Visual Saliency**\n",
        "\n",
        "**a. Medical Imaging**\n",
        "\n",
        "\n",
        "- Visual saliency in medical imaging helps in abnormality detection and computer-aided diagnosis. \n",
        "- Most of the saliency models used in medical imaging are developed by considering the context of the problem and knowledge of the radiologists. \n",
        "- These saliency models combine bottom-up and top-down attention models using domain knowledge\n",
        "\n",
        "Radiologist attention modelling - https://drive.google.com/file/d/1pFSqqcRvuJBIsUU9LQuCTfOqGJY72OYf/view?usp=sharing\n",
        "\n",
        "Saliency maps of brain MRI with tumor - https://drive.google.com/file/d/1JPU7x0XV8Wb9-cpUHZIHAGWtIwf-8SsQ/view?usp=sharing\n",
        "\n",
        "\n",
        "**b. Disaster Management and Visual Surveillance**\n",
        "\n",
        "- Visual saliency helps in efficiently sleeting any abnormal activity in the images/video.\n",
        "\n",
        "\n",
        "\n",
        "- Fire localization and detection - https://drive.google.com/file/d/1MPGDiRaJ1c2x0k-4WhX3cT1vpb99vQkT/view?usp=sharing\n",
        "\n",
        "- Border crossing - https://drive.google.com/file/d/1UhQdxE_X9sk1rV7POOA_UkpMqWHnXKkn/view?usp=sharing\n",
        "\n",
        "\n",
        "**c. Media Recommendation Systems**\n",
        "\n",
        "- Based on viewer’s interest, personalized media content recommendation can be made.  \n",
        "\n",
        "- https://drive.google.com/file/d/115bUMfDMM4z4qhHw95Yync1ZU4E-mX8J/view?usp=sharing\n",
        "\n",
        "**d. Information Summarization**\n",
        "\n",
        "Visual saliency helps in removing the non-informative data and extract and summarize the information data e.g. \n",
        "- Information summarization of huge visual surveillance networks. \n",
        "- Personalized movie trailer generation based on users’ interest. \n",
        "\n",
        "https://drive.google.com/file/d/1gNd6hY8K0SpY8BIlRAxz_ZQ7Sow5L6fN/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUH0KEZ9dwl7"
      },
      "source": [
        "# **4   Challenges in Saliency Computation**\n",
        "\n",
        "**a. Challenges**\n",
        "\n",
        "- There is no simple single basic feature or set of features that adequately characterizes what comprises salient content across all images. \n",
        "- In various cases, saliency is subjective and varies from person to person.\n",
        "- Little knowledge about the human underlying neural basis for such computation \n",
        "\n",
        "\n",
        "**b. Multimodal Data Analysis and Saliency Computation**\n",
        "\n",
        "In recent studies it is observed that the robustness and performance of saliency computation and its accuracy can be improved by incorporating the following modalities:\n",
        "-\tVisual modality (imaging)\n",
        "-\tAudio modality\n",
        "-\tNeuronal modality \n",
        "\n",
        "EEG - https://drive.google.com/file/d/1b0qXR7Ovzg0-zzvpCPMk0r_UQMPvK8E0/view?usp=sharing\n",
        "\n",
        "Multimodal media recommendation - https://drive.google.com/file/d/1YOVKFQOgtAzS76J2u_QbTWhHxk3Vbl2F/view?usp=sharing\n",
        "\n",
        "EEG based user attention examples- \n",
        "1. https://drive.google.com/file/d/1pKLjGOgF4c0bK_jq9Fm5SUh_d1rc5iXY/view?usp=sharing\n",
        "2. https://drive.google.com/file/d/1Unie-Agem0xzJz4i2z_OBUKrz9jIOZ24/view?usp=sharing\n",
        "3. https://drive.google.com/file/d/1mRf8ENPiArLjangkbP4RIfpMO9CLRO3J/view?usp=sharing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lRtL-9Frd5M"
      },
      "source": [
        "# **5 Visual Saliency Resources**\n",
        "\n",
        "1. http://ilab.usc.edu/borji/cvpr2013/\n",
        "2. https://www.pyimagesearch.com/2018/07/16/opencv-saliency-detection/\n",
        "3. https://pythonawesome.com/visual-saliency-transformer-with-python/\n",
        "4. https://authors.library.caltech.edu/65361/\n",
        "5. http://www.scholarpedia.org/article/Visual_salience\n",
        "\n",
        "**Example Codes:**\n",
        "- Examplecode1.ipynb\n",
        "- Examplecode2.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srd4YlVpswE1"
      },
      "source": [
        "# **6 Summary of the Future Data Hackers Session 4**\n",
        "\n",
        "- Introduction to Computer Vision\n",
        "- Use of a range of visual saliency libraries\n",
        "- Hands-on practice with Salient Object Detection tasks\n",
        "- Examples of visual saliency and its applications in different domains\n",
        "- Challenges in saliency computation and Multimodal saliency approaches\n",
        "\n",
        "\n",
        "Thank you! \n",
        "\n",
        "**Dr Irfan Mehmood**\n",
        "\n",
        "Assistant Professor of Applied Artificial Intelligence\n",
        "\n",
        "Faculty of Engineering & Informatics\n",
        "University of Bradford\n",
        "\n",
        "Email: i.mehmood4@bradford.ac.uk\n",
        "\n",
        "02/08/21\n"
      ]
    }
  ]
}