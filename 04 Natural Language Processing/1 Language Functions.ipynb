{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1mgqESl66JJ0tPFPB8Xx0Ha3J_0VrwEI2","timestamp":1681475488572},{"file_id":"1GZPgRhl5-tvYAjK9E3HbNnRi8SQ3WYS-","timestamp":1669997081040},{"file_id":"1TyXPH5Lc2zvcebXAyuhxWTl4jCFr6h8I","timestamp":1636680076474},{"file_id":"16DgTbg0Ngr0J6irQnoKgip5q1B3983_7","timestamp":1626700476570},{"file_id":"1G23gx7B2f7c-3OwtLHA4th5nUshGxquH","timestamp":1626656205487}],"collapsed_sections":["L2lIItWLGXZA","QRlfWmXpHevs","0PmO8JMEJAHj","YBSr7PlKJNF-","FhZrQ4XXPWgY","yLCdkAwZPlqR","2hqWrCcdPlV4","v307tiVPYFf5","d0FdPrpTaYZq","veaCUvqjdC2-","d1EBjX4cdVCB","eEGQbpibfb4r","EsR8ARhXgaD5","uU815pV3gag7","DNt_zBOXmIbe","S1_nTTRKnqT8","aSoC6Br7vJEe","3JyLQEzzorxR","MAkPVT9UeUIc","BqC8YVkKemk5","GrP0fxO7lPnu","QOw-Kt3xlrWE","8Tji99M6l6do","sWSELixQtDsP","aVraCAWk487P","DD6hbE6dpdPX","-lRtL-9Frd5M","Srd4YlVpswE1"],"toc_visible":true,"authorship_tag":"ABX9TyMXmm8mpb4WO5JOr9jM2q2W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"N-TBE56W8Cpf"},"source":["# **The Power of Natural Language Processing**\n","\n","**Natural Language Processing is** about how we interact with computers and human language. NLP is a branch of artificial intelligence (AI).  AI is the science and engineering of making intelligent machines.\n","\n","[Where does NLP fit with AI?](https://drive.google.com/file/d/1NzSueuixQGYtJJWnKnx70T14kPvwyZNA/view?usp=sharing)\n","\n","NLP involves techniques, trends  and technologies deployed in a   range of powerful business cases and applications.  The global pandemic has brought the future forward by five years, due to AI adoption, investment, and latest NLP language models.\n","\n","[NLP Applications] [ranging examples](https://drive.google.com/file/d/1_uBRrJ7ZtRfC4l1q3lrjgTlIO90da93f/view?usp=sharing)  \n","\n","[Everyday NLP use](https://drive.google.com/file/d/1MzPYEa6myLDq_yJ0cavWxeVRkq3G0dZE/view?usp=sharing)\n","\n","**Aim:** To grasp  an awareness of NLP applications and explore with  hands-on experience some  powerful NLP techniques used in solutions.  We will also identify some of the challenges of NLP.\n","\n","**Objectives**\n","*   To use a range of NLP libraries, techniques and datasets for specific use cases and explore data\n","*   To create a simple chatbot and appreciate its limitations"]},{"cell_type":"markdown","metadata":{"id":"Rg-7vcdhF9pL"},"source":["# **1   Examples of natural language communications**\n","\n","*   Conversations between people\n","*   Communicating with a hearing-impaired friend via sign language\n","*   Learning a foreign language to prepare for travel abroad\n","*   Using a smartphone to read a menu in another language\n","*   Reading/writing text messagesList item\n","*   A blind colleague reading braille or listening to a screen reader describe what’s on a computer screenList item\n","*   Receiving a client email in Spanish, translating it and responding in English knowing that your client can easily translate your email back to Spanish\n","and much more.\n","\n","NLP is performed on text collections (corpora, plural of corpus)\n","\n","*   Tweets\n","*   Facebook Posts\n","*   Conversations\n","*   Movie Reviews\n","*   Documents, Books and many more\n","\n","Nuances of meaning make natural lanaguage understanding difficult \n","\n","*   Text's meaning can be influenced by context and reader's \"world view\"\n","*   Text is highly contexutal, ambigioius and irregular"]},{"cell_type":"markdown","metadata":{"id":"8XP1fxh83xjD"},"source":["# **2   Natural Language Processing**\n","\n","**Objectives**\n","\n","*   Perform NLP tasks fundamental to most case studies\n","*   Use Libraries - TextBlob, Textatistic and spaCy \n","*   Tokenise text into words and sentences\n","*   Part-of-speech tagging(POS)\n","*   Sentiment analysis fot determining whether text is **positive, negative or **neutral** **\n","*   Detect the language of text and translate between languages\n","*   Word roots via stemming and lemmatization\n","*   Spelling checking and correction\n","*   Remove stops words in text\n","*   Create word cloud visualisations\n","*   Readability assessment\n","*   Named entity recognition and similarity detection\n","*   Review one example domain - a chatbot \n","*   Identify a couple of  challenges of NLP"]},{"cell_type":"markdown","metadata":{"id":"q7IMGW3LbxcI"},"source":["## **NLTK(Natural Language Toolkit)** \n","\n","NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries.\n","NLTK has been called “a wonderful tool for teaching and working in, computational linguistics using Python,” and “an amazing library to play with natural language.”\n","Natural Language Processing with Python provides a practical introduction to programming for language processing. I highly recommend this book to people beginning in NLP with Python.\n","Downloading and installing NLTK\n","1.\tInstall NLTK: run pip install nltk\n","2.\tTest installation: run python then type import nltk\n","\n","**Installing NLTK Packages**\n","Import NLTK and run nltk.download().This will open the NLTK downloader from where you can choose the corpora and models to download. You can also download all packages at once.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RCCr7eYLf3s4"},"source":["# **Downloading and installing NLTK**\n","\n","NLTK(Natural Language Toolkit) is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries.\n","\n","Natural Language Processing with Python provides a practical introduction to programming for language processing.\n","\n","# **Installing NLTK Packages**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_C_zh5NiNdC","executionInfo":{"status":"ok","timestamp":1681475674216,"user_tz":-60,"elapsed":10526,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"0d214623-d901-43f4-c040-b808b03cc7c3"},"source":["import nltk\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('popular', quiet=True) # for downloading packages\n","nltk.download('punkt') # first-time use only\n","nltk.download('wordnet') # first-time use only\n","nltk.download('brown') # first-time use only\n","nltk.download('stopwords') # first-time use only"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package brown to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/brown.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"o0k_g0H93xUg"},"source":["# **TextBlob Library**\n","\n","A library build on top of NLTK\n","Some NLP tasks TextBlob can do:\n","\n","Sentiment analysis—determining whether text has positive, neutral or negative sentiment.\n","Inter-language translation and language detection powered by Google Translate.\n","\n","*   **Tokenization**—splitting text into pieces called tokens, which are meaningful units, such as words and numbers\n","\n","*   **Parts-of-speech (POS) tagging**—identifying each word’s part of speech, such as noun, verb, adjective, etc.\n","*   **Noun phrase extraction**—locating groups of words that represent nouns, such as “red brick factory.”\n","\n","*   The phrase “red brick factory” illustrates why natural language is such a difficult subject. Is a “red brick factory” a factory that makes red bricks? Is it a red factory that makes bricks of any colour? Is it a factory built of red bricks that makes products of any type? In today’s music world, it could even be the name of a rock band or the name of a game on your smartphone.\n","\n","*   **Sentiment analysis**—determining whether text has positive, neutral or negative sentiment\n","*   **Inter-language translation** and language detection powered by Google Translate.\n","*   **Inflection—pluralizing **and singularizing words. There are other aspects of inflection that are not part of TextBlob.\n","*   **Spell checking** and spelling correction.\n","*   **Stemming—reducing words** to their stems by removing prefixes or suffixes. For example, the stem of “varieties” is “varieti.”\n","*   **Lemmatization—**like stemming, but produces real words based on the original words’ context. For example, the lemmatized form of “varieties” is “variety.”\n","*   **Word frequencies**—determining how often each word appears in a corpus.\n","*   **WordNet integration **for finding word definitions, synonyms and antonyms.\n","*   **Stop word elimination—**removing common words, such as a, an, the, I, we, you and more to analyze the important words in a corpus.\n","*   n-grams—producing sets of consecutive words in a corpus for use in identifying words that frequently appear adjacent to one another.\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OIN7vEQV9deD","executionInfo":{"status":"ok","timestamp":1681475684608,"user_tz":-60,"elapsed":10399,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"73a50a90-9ce7-4c5c-c310-68bc80426aaf"},"source":["# Setup\n","!pip install textblob\n","!pip install wordcloud\n","!pip install spacy\n","\n","import textblob.download_corpora\n","\n","from textblob import TextBlob"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: textblob in /usr/local/lib/python3.9/dist-packages (0.17.1)\n","Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.9/dist-packages (from textblob) (3.8.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.9/dist-packages (1.8.2.2)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.9/dist-packages (from wordcloud) (1.22.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from wordcloud) (8.4.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from wordcloud) (3.7.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (23.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (3.0.9)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (2.8.2)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->wordcloud) (5.12.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (67.6.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.7)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n"]}]},{"cell_type":"code","metadata":{"id":"918nVJxxcqsU"},"source":["# Importing the necessary libraries\n","import io\n","import imageio\n","import random\n","import string # to process standard python strings\n","import warnings\n","import numpy as np\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","import warnings\n","warnings.filterwarnings('ignore')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Fz_kNMl_VYI","executionInfo":{"status":"ok","timestamp":1681475684609,"user_tz":-60,"elapsed":14,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"551d5a63-d018-472a-c001-96611188bb77"},"source":["text = 'Today is a beautiful day. Tomorrow looks like bad weather.'\n","blob = TextBlob(text)\n","blob\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"ZqV7dCSj_vh_"},"source":["**TextBlob, Sentences and Words Support String Methods and Comparisons**\n","Sentences, Words and TextBlobs inherit from BaseBlob, which defines many common methods and properties\n","\n","**Tokenizing Text into Sentences and Words**\n","\n","Getting a list of sentences"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EH7kvIEI_WUP","executionInfo":{"status":"ok","timestamp":1681475684609,"user_tz":-60,"elapsed":11,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"cb459cd6-281c-4cca-cbd9-2d7b73db11eb"},"source":["blob.sentences\n","blob.words\n","# TextBlob contains word objects"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["WordList(['Today', 'is', 'a', 'beautiful', 'day', 'Tomorrow', 'looks', 'like', 'bad', 'weather'])"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"v_Q7kGC7AeIw"},"source":["# **Parts-of-Speech Tagging**\n","\n","1.   Evaluate words based on context to determine parts of speech, which can help determine meaning\n","2.   Eight primary English parts of speech\n","*   Nouns, pronouns, verbs, adjectives, adverbs, prepositions, conjunctions and interjections (words that express emotion and that are typically followed by punctuation, like “Yes!” or “Ha!”)\n","*   Many subcategories\n","*   Some words have multiple meanings.  E.g., “set” and “run” have hundreds of meanings each!\n","*   TextBlob uses a PatternTagger to determine parts-of-speech\n","*  Uses pattern library POS tagging with Pattern's **63 parts-of-speech tags**\n","\n","*   **NN**—a singular noun or mass noun\n","*   **VBZ**—a third person singular present verb\n","*   **DT**—a determiner (the, an, that, this, my, their, etc.)\n","*   **JJ**—an adjective\n","*  **NNP**—a proper singular noun\n","*   **IN**—a subordinating conjunction or preposition\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DJZoKGGiBr2G","executionInfo":{"status":"ok","timestamp":1681475684610,"user_tz":-60,"elapsed":11,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"e55629ba-67a7-4b55-a9da-2890e1e1e3b3"},"source":["blob\n","blob.tags"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Today', 'NN'),\n"," ('is', 'VBZ'),\n"," ('a', 'DT'),\n"," ('beautiful', 'JJ'),\n"," ('day', 'NN'),\n"," ('Tomorrow', 'NNP'),\n"," ('looks', 'VBZ'),\n"," ('like', 'IN'),\n"," ('bad', 'JJ'),\n"," ('weather', 'NN')]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"zfygS5cQFwHv"},"source":["# **Extracting Noun Phrases**\n","\n","Preparing to purchase a water ski\n","\n","*   Might search for “best water ski”—“water ski” is a noun phrase\n","\n","*   For best results, search engine must parse the noun phrase properly\n","*   Try searching for “best water,” “best ski”, “water ski” and “best water ski” and see what you get\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u4P5Wkz8BtlS","executionInfo":{"status":"ok","timestamp":1681475687896,"user_tz":-60,"elapsed":3295,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"c761a8a8-841b-4ee0-b7d4-6c1f7f3b277f"},"source":["blob\n","blob.noun_phrases\n","\n","# A Word can represent a noun phrase with multiple words."],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["WordList(['beautiful day', 'tomorrow', 'bad weather'])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"L2lIItWLGXZA"},"source":["# **Sentiment Analysis with TextBlob’s Default Sentiment Analyzer**\n","\n","*   Determines whether text is positive, neutral or negative.\n","*   One of the most common and valuable NLP tasks \n","*   Consider the positive word “good” and the negative word “bad\"\n","*   Alone they are positive and negative, respectively, but...\n","*   The food is not good — clearly has negative sentiment\n","*   The movie was not bad — clearly has positive sentiment (but not as positive as The movie was excellent!)\n","*   Complex machine-learning problem, but libraries like TextBlob can do it for you\n","\n","# **Getting the Sentiment of a TextBlob**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6D5M9Z7qBuIV","executionInfo":{"status":"ok","timestamp":1681475687896,"user_tz":-60,"elapsed":22,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"2e9deac7-b99e-4e50-de25-0aea71cd5091"},"source":["text = 'Today is a beautiful day. Tomorrow looks like bad weather.'\n","blob = TextBlob(text)\n","blob\n","\n","blob.sentiment\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentiment(polarity=0.07500000000000007, subjectivity=0.8333333333333333)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"bfiNp68UBut-"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRlfWmXpHevs"},"source":["*   Polarity is the sentiment — from -1.0 (negative) to 1.0 (positive) with 0.0 being neutral.\n","*   Subjectivity is a value from 0.0 (objective) to 1.0 (subjective).\n","\n","## **Getting the polarity and subjectivity from the Sentiment Object** **bold text**\n","\n","*   %precision magic specifies the default precision for standalone float objects and float objects in built-in types like lists, dictionaries and tuples:\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ADiAyVHGBvN5","executionInfo":{"status":"ok","timestamp":1681475687897,"user_tz":-60,"elapsed":19,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"34a19b09-111d-4098-b693-8b1086884e51"},"source":["%precision 3"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'%.3f'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmkGN83rBvp_","executionInfo":{"status":"ok","timestamp":1681475687897,"user_tz":-60,"elapsed":18,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"cd1b50bb-7d14-486e-81d6-536667999ed9"},"source":["blob.sentiment.polarity"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.075"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_2KhoY6MIv0q","executionInfo":{"status":"ok","timestamp":1681475687897,"user_tz":-60,"elapsed":18,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"41c44ff0-6e8c-48ac-e6f6-1af9688f9867"},"source":["blob.sentiment.subjectivity"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.833"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"0PmO8JMEJAHj"},"source":["# **Getting the Sentiment of a Sentence**\n","One is positive (0.85) and one is negative (-0.6999999999999998), which might explain why the entire TextBlob’s sentiment was close to 0.0 (neutral)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ts_BafAXJYVq","executionInfo":{"status":"ok","timestamp":1681475687897,"user_tz":-60,"elapsed":17,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"f5274647-452e-408c-bcfc-58bcdc50a527"},"source":["blob\n","for sentence in blob.sentences:\n","    print(sentence.sentiment)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment(polarity=0.85, subjectivity=1.0)\n","Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666)\n"]}]},{"cell_type":"markdown","metadata":{"id":"YBSr7PlKJNF-"},"source":["## **Sentiment Analysis with the NaiveBayesAnalyzer**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XSffZaVJn_m","executionInfo":{"status":"ok","timestamp":1681475692048,"user_tz":-60,"elapsed":4168,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"bac8ebd8-ad27-478f-ee06-c00c2dc7a60f"},"source":["from textblob.sentiments import NaiveBayesAnalyzer\n","blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n","blob\n","blob.sentiment\n","for sentence in blob.sentences:\n","    print(sentence.sentiment)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment(classification='pos', p_pos=0.8117563121751951, p_neg=0.18824368782480477)\n","Sentiment(classification='neg', p_pos=0.174363226578349, p_neg=0.8256367734216521)\n"]}]},{"cell_type":"markdown","metadata":{"id":"dijYy8QVKDcn"},"source":["# **Language Detection and Translation**\n","\n","\n","*   **Google Translate, Microsoft Bing Translator** and others can translate between scores of languages instantly\n","*   Now working on near-real-time translation \n","*   Converse in real time with people who do not know your natural language\n","\n","\n","*   Can specify a source language explicitly by passing the from_lang keyword argument to the translate method\n","chinese = blob.translate(from_lang='en', to='zh')\n","*   Can specify a source language explicitly by passing the from_lang keyword argument to the translate method\n","*   For example - chinese = blob.translate(from_lang='en', to='zh')\n","*   from_lang and to use iso-639-1 language codes   - Google Translate’s list of supported languages"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r_FK_Uc1J-wC","executionInfo":{"status":"ok","timestamp":1681475692049,"user_tz":-60,"elapsed":21,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"outputId":"517287d9-e548-46c8-e68b-1d86a8257249"},"source":["blob\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"uss3ztA4OLXL"},"source":["# blob.detect_language()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v43u23DYNlVe","executionInfo":{"status":"error","timestamp":1681475692050,"user_tz":-60,"elapsed":20,"user":{"displayName":"Kulvinder Panesar","userId":"01207945261942467346"}},"colab":{"base_uri":"https://localhost:8080/","height":182},"outputId":"1adf2bf4-3446-41f3-9f00-a2027252c47b"},"source":["#spanish = blob.translate(to='es')\n","spanish\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-270c55e78c4b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#spanish = blob.translate(to='es')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspanish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'spanish' is not defined"]}]},{"cell_type":"code","metadata":{"id":"qS6q691dN4vQ"},"source":["#chinese = blob.translate(to='zh')\n","chinese"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ROliY1IaODUC"},"source":["#spanish.translate()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZG2FuFXOlMA"},"source":["#chinese.translate() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FhZrQ4XXPWgY"},"source":["## **Inflection: Pluralization and Singularization¶**\n","\n","*   Inflections are different forms of the same words, such as singular and plural (like “person” and “people”) and different verb tenses (like “run” and “ran”)\n","*   When you’re calculating word frequencies, you might first want to convert all inflected words to the same form for more accurate word frequencies\n"]},{"cell_type":"code","metadata":{"id":"1btiotfYPN9A"},"source":["from textblob import Word\n","index = Word('index')\n","index.pluralize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OEiUOysJQVjL"},"source":["cacti = Word('cacti')\n","cacti.singularize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y-aamyYoPOVo"},"source":["animals = TextBlob('dog cat fish bird').words\n","animals.pluralize()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yLCdkAwZPlqR"},"source":["# **Spell Checking and Correction**\n","\n","*   For natural language processing tasks, it’s important that the text be free of spelling errors\n","*   A Word’s spellcheck method returns a list of tuples containing possible correct spellings and confidence values\n","*   Assume we meant to type “they” but misspelled it as “theyr”\n"]},{"cell_type":"code","metadata":{"id":"lP_bIGcPYEob"},"source":["from textblob import Word\n","word = Word('theyr')\n","word.spellcheck()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hynIfmcNY5mV"},"source":["word.correct()  # chooses word with the highest confidence value"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2hqWrCcdPlV4"},"source":["# **Correction**\n","*   Word with the highest confidence value might not be the correct word for the given context\n","*   TextBlobs, Sentences and Words all have a correct method that you can call to correct spelling\n","*   Calling correct on a Word returns the correctly spelled word that has the highest confidence value\n"]},{"cell_type":"code","metadata":{"id":"8AmUiI3BYFFp"},"source":["from textblob import TextBlob\n","sentence = TextBlob('Ths sentense has missplled wrds.')\n","sentence.correct()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v307tiVPYFf5"},"source":["# **Normalization: Stemming and Lemmatization**\n","\n","*   Stemming removes a prefix or suffix from a word leaving only a stem, which may or may not be a real word\n","*   Lemmatization is similar, but factors in the word’s part of speech and meaning and results in a real word\n","*   Both normalize words for analysis\n","*   Before calculating statistics on words in a body of text, you might convert all words to lowercase so that capitalized and lowercase words are not treated differently.*   You might want to use a word’s root to represent the word’s many forms. E.g., treat \"program\" and \"programs\" as \"program\""]},{"cell_type":"code","metadata":{"id":"jAoNWx2xPOsj"},"source":["from textblob import Word\n","word = Word('varieties')\n","word.stem()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b314fF5SPPFg"},"source":["word.lemmatize()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d0FdPrpTaYZq"},"source":["# **Word Frequencies**\n","\n","\n","*   Various techniques for detecting similarity between documents rely on word frequencies\n","*   TextBlob can count word frequencies for you\n","*   When you read a file with Path’s read_text method, it closes the file immediately after it finishes reading the file\n","\n","*   Access the word frequencies through the TextBlob’s word_counts dictionary"]},{"cell_type":"code","metadata":{"id":"YGR0jax1avdj"},"source":["# Upload the ''RomeoAndJuliet.txt' file from a source\n","\n","from google.colab import files\n","data_to_load = files.upload()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JIBDZDQjcwB-"},"source":["blob = TextBlob('RomeoAndJuliet.txt')\n","blob.noun_phrases.count('lady capulet')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"veaCUvqjdC2-"},"source":["# **Getting Definitions, Synonyms and Antonyms from WordNet**\n","\n","**WordNet** is a English word database created by Princeton University\n","**TextBlob** uses NLTK’s WordNet interface to look up word definitions, and get **synonyms** and **antonyms**\n","\n","(skipping this- but easy to do)"]},{"cell_type":"markdown","metadata":{"id":"d1EBjX4cdVCB"},"source":["# **Deleting Stop Words**\n","\n","\n","*   Common words that are often removed before analysis because they do not provide useful information\n","*   Returned by the NLTK stopwords module’s words function\n","\n","[Host of stop words found here: ](https://drive.google.com/file/d/155URmKRv7Ao6uzF9vj4A9oJoaFjKTUvi/view?usp=sharing)\n","\n"]},{"cell_type":"code","metadata":{"id":"z_v_8pl6erFW"},"source":["from nltk.corpus import stopwords\n","stops = stopwords.words('english')\n","from textblob import TextBlob\n","blob = TextBlob('Today is a beautiful day.')\n","[word for word in blob.words if word not in stops]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fZT-zSoZfTeU"},"source":[]},{"cell_type":"markdown","metadata":{"id":"eEGQbpibfb4r"},"source":["# **n-grams**\n","**n-gram** a sequence of n text items, such as letters in words or words in a sentence.### \n","\n","**Used to** identify letters or words that frequently appear adjacent to one another\n","Predictive text input\n","\n","*   Predictive text input\n","*   Speech-to-text\n"]},{"cell_type":"code","metadata":{"id":"tPS1lZRUJlqb"},"source":["from textblob import TextBlob\n","text = 'Today is a beautiful day. Tomorrow looks like bad weather.'\n","blob = TextBlob(text)\n","#  TextBlob’s ngrams method produces a list of WordList n-grams of length three by default—known as trigrams\n","\n","#  Use keyword argument n to produce n-grams of any desired length"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kjHQ0gXGgHWH"},"source":["blob.ngrams()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FGgEuWltgL_R"},"source":["blob.ngrams(n=5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"chBv6GYjgXWe"},"source":["# **Visualizing Word Frequencies with Bar charts  and Word Clouds**\n","\n","Can enhance your corpus analyses\n","\n","\n","*   A bar chart quantitatively visualizes the top 20 words in Romeo and Juliet as bars representing each word and its frequency.\n","*   A word cloud qualitatively visualizes more frequently occurring words in larger fonts and less frequently occurring words in smaller fonts.\n","\n","**Examples**\n","\n","[Masked image wordcloud](https://drive.google.com/file/d/1DokgIjWuesvTx9zup7a8crJbDejPRNq0/view?usp=sharing)\n","\n","[Bar chart word frequency](https://drive.google.com/file/d/19Jt2akrK4BHuIjYIOPV9moSv72t7WHFk/view?usp=sharing)\n","\n"]},{"cell_type":"code","metadata":{"id":"2rPcycwLu1EK"},"source":["%matplotlib inline\n","\n","# Loading the data\n","from pathlib import Path\n","from textblob import TextBlob\n","\n","import re\n","file = open(Path('/content/RomeoAndJuliet.txt'), \"r\")\n","doclist = [ line for line in file ]\n","docstr = '' . join(doclist)\n","sentences = re.split(r'[.!?]', docstr)\n","print('All sentences - method 1')\n","print(2 * \"\\n\")\n","print('sentences', sentences)\n","print('length of sentences', len(sentences))\n","\n","blob = TextBlob(Path('/content/RomeoAndJuliet.txt').read_text())\n","print('All sentences')\n","print(2 * \"\\n\")\n","print(blob.sentences)\n","print(2 * \"\\n\")\n","print('All words')\n","print(blob.words)\n","print(2 * \"\\n\")\n","print('All tags')\n","print(blob.tags)\n","print(2 * \"\\n\")\n","print('All noun phrases')\n","print(2 * \"\\n\")\n","print(blob.noun_phrases)\n","print(2 * \"\\n\")\n","\n","print('All counts')\n","\n","print('Senetence length is ', len(blob.sentences))\n","\n","words =blob.word_counts\n","print('Word  length is ', words.items())\n","\n","\n","print('Tag length ', blob.tags.count)\n","\n","\n","print('Noun phrase count', blob.noun_phrases.count)\n","#from google.colab import files\n","#uploaded = files.upload()\n","# blob = nlp('RomeoAndJuliet.txt')\n","\n","#Load NLTK stop words\n","\n","from nltk.corpus import stopwords\n","stop_words = stopwords.words('english')\n","\n","#Getting the Word Frequencies\n","# Get word frequency tuples\n","\n","items = blob.word_counts.items()\n","print (items)\n","#Eliminating the Stop Words\n","#The expression item[0] gets the word from each tuple so we can check whether it’s in stop_words\n","pattern=['n\\'t', 'points', 'th', 'um', 'uh', 'em', 'oh', 'na','ges']\n","\n","\n","\n","items = [item for item in items if item[0] not in stop_words]\n","items = [item for item in items if item[0] not in pattern]\n","\n","\n","#Sorting the Words by Frequency\n","#Sort the tuples in items in descending order by frequency\n","#To specify the tuple element to sort by, use the itemgetter function from the Python Standard Library’s operator module\n","\n","\n","from operator import itemgetter\n","\n","sorted_items = sorted(items, key=itemgetter(1), reverse=True)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQcamSVswWW9"},"source":["# **Getting the Top 20 Words**\n","\n","TextBlob tokenizaton splits all contractions at their apostrophes and counts the total number of apostrophes as one of the “words”\n","\n","Romeo and Juliet has many contractions\n","\n","\n","If you display sorted_items[0], you’ll see that they are the most frequently occurring “word” with 867 of them\n","\n","(In some locales this does not happen and element 0 is indeed 'romeo')\n","We ignore element 0"]},{"cell_type":"code","metadata":{"id":"3JfWySz2wgRD"},"source":["top20 = sorted_items[0:21]\n","# https://stackoverflow.com/questions/16819222/how-to-return-dictionary-keys-as-a-list-in-python\n","\n","\n","print (top20) \n","\n","\n","# my_dict = {\"a\" : 1, \"b\" : 2}\n","# for key in sorted_items:\n","#    if sorted_items[items] == 'n\\'t' or 'points' or 'th' or 'um' or 'uh' or 'ges':\n","#      sorted_items[items].pop()\n","\n","\n","# for key, value in sorted_items:\n","#    print(key, ' : ', value)\n","#    if key == #: \n","#      sorted_items[items].pop(key)\n","\n","#y= ['n't', 'points', 'th', 'um', 'uh',  'um', 'ges']\n","#new_dict = {}\n","#for key, value in top10:\n","#    if key is not 'n\\'t' or 'points' or 'th' or 'um' or 'uh' or 'ges':\n","#        new_dict[key] = value\n","#top10 = new_dict\n","# print(top10)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"thXccQtsw6IF"},"source":["Convert top20 to a DataFrame"]},{"cell_type":"code","metadata":{"id":"9m1FHnMawmKn"},"source":["import pandas as pd\n","df = pd.DataFrame(top20, columns=['word', 'count'])  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3UV6964wrsA"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NWrRUzU4xFfC"},"source":[]},{"cell_type":"code","metadata":{"id":"YvsMiTwaxGAT"},"source":["axes = df.plot.bar(x='word', y='count', legend=False)\n","\n","import matplotlib.pyplot as plt\n","\n","plt.gcf().tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6IoS2qq2gZMX"},"source":["# **Named Entity Recognition with spaCy**\n","\n","*   NLP can determine what a text is about\n","*   Named entity recognition attempts to locate and categorize items\n","*   dates, times, quantities, places, people, things, organizations and more\n","\n","# **Loading the Language Model**\n","\n","*   spaCy docs recommend the variable name nlp.\n","\n","# **Creating a spaCy Doc**\n","\n","*   Use the nlp object to create a spaCy Doc object representing the document to process\n"]},{"cell_type":"code","metadata":{"id":"pbljr_tQjzK9"},"source":["import spacy\n","nlp = spacy.load('en') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H4Pb3lKCkV8A"},"source":["document = nlp('In 1994, Tim Berners-Lee founded the ' + \n","    'World Wide Web Consortium (W3C), devoted to ' +\n","    'developing web technologies')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EsR8ARhXgaD5"},"source":["# **Getting the Named Entities**\n","\n","\n","*   Returns tuple of Spans representing the named entities\n","*   Spans have many properties\n","*   Display text (the entity's text) and label_ (the kind of entity)"]},{"cell_type":"code","metadata":{"id":"uWP92LkPkxba"},"source":["for entity in document.ents:\n","    print(f'{entity.text}: {entity.label_}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uU815pV3gag7"},"source":["# **Similarity Detection with spaCy**\n","\n","*   Analyzing documents to determine how alike they are\n","*   Who wrote the works of William Shakespeare? Sir Francis Bacon? Christopher Marlowe? Others?\n","*   Comparing word frequencies can reveal writing-style similarities\n","*   We’ll compare Doc objects for Shakespeare’s Romeo and Juliet and Christopher Marlowe's Edward the Second\n","\n","Loading the Language model - spaCy's medium sized model (~91MB) for better accuracy\n","\n"]},{"cell_type":"code","metadata":{"id":"6gta5p7VlegW"},"source":["# Setup\n","# For accuracy models\n","\n","# spacy's small sized model (<40MB) - baseline model already installed\n","\n","# spaCy's medium sized model (~91MB) for better accuracy\n","# !pip install spacy download en_core_web_md\n","\n","# For spaCy's best accuracy, you can load the large sized model (~788mb)\n","# !pip install  spacy download en_core_web_lg  (not run for due to the bandwidth) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L1ZYlqafmF2g"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DNt_zBOXmIbe"},"source":["# **Creating the spaCy Docs**\n","\n","*   Create two Doc objects—one for Romeo and Juliet and one for Edward the Second:\n","\n"]},{"cell_type":"code","metadata":{"id":"8ZxA66Agmc-m"},"source":["#Upload 'Romeo and Juliet' and 'Edward the Second' \n","\n","from google.colab import files\n","uploaded = files.upload()\n","document1 = nlp('RomeoAndJuliet.txt')\n","from google.colab import files\n","uploaded = files.upload()\n","document2 = nlp('RomeoAndJuliet.txt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S1_nTTRKnqT8"},"source":["# **Comparing the Books’ Similarity**\n","\n","*   Returns a value from 0.0 (not similar) to 1.0 (identical) indicating how similar the documents are"]},{"cell_type":"code","metadata":{"id":"iPD5QaiLn6ie"},"source":["document1.similarity(document2)\n","# This model uses the baseline model for accuacy. For better results use the alternative larger models (best result is  0.981459724155179)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aSoC6Br7vJEe"},"source":["# **Chatbot Practice**"]},{"cell_type":"markdown","metadata":{"id":"3JyLQEzzorxR"},"source":["## **Building a Simple Chatbot from Scratch in Python (using NLTK)**\n","\n","![Alt text](https://cdn-images-1.medium.com/max/800/1*pPcVfZ7i-gLMabUol3zezA.gif)\n","\n","History of chatbots dates back to 1966 when a computer program called ELIZA was invented by Weizenbaum. It imitated the language of a psychotherapist from only 200 lines of code. You can still converse with it here: [Eliza](http://psych.fullerton.edu/mbirnbaum/psych101/Eliza.htm?utm_source=ubisend.com&utm_medium=blog-link&utm_campaign=ubisend). \n","\n","On similar lines let's create a very basic chatbot utlising the Python's NLTK library.It's a very simple bot with hardly any cognitive skills,but still a good way to get into NLP and get to know about chatbots.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"w9a-Ht08I7vZ"},"source":["**What is a Chatbot?**\n","\n","A chatbot is an artificial intelligence-powered piece of software in a device (Siri, Alexa, Google Assistant etc), application, website or other networks that try to gauge consumer’s needs and then assist them to perform a particular task like a commercial transaction, hotel booking, form submission etc . Today almost every company has a chatbot deployed to engage with the users. Some of the ways in which companies are using chatbots are:\n","•\tTo deliver flight information\n","•\tto connect customers and their finances\n","•\tAs customer support\n","\n","*   To deliver flight information\n","*   to connect customers and their finances\n","*   as customer support\n","\n","The possibilities are (almost) limitless.\n","\n","**Two types of chatbots**: rule based and self learning \n","\n","1.   **Rule based approach** -  a bot answers questions based on some rules on which it is trained on. The rules defined can be very simple to very complex. The bots can handle simple queries but fail to manage complex ones.\n","2.   **Self-learning bots** are the ones that use some Machine Learning-based approaches and are definitely more efficient than rule-based bots. These bots can be of further two types: Retrieval Based or Generative\n"]},{"cell_type":"markdown","metadata":{"id":"MAkPVT9UeUIc"},"source":["# **Read in a Chatbot knowledge base/dataset**\n","For our example, we will be using the Wikipedia page for chatbots as our corpus. \n","Copy the contents from the page and place it in a text file named ‘chatbot.txt’. However, you can use any corpus of your choice."]},{"cell_type":"code","metadata":{"id":"E4tIclQIeOVl"},"source":["# It will prompt you to select a file. Click on “Choose Files” then select and upload the file. Wait for the file to be 100% uploaded.\n","\n","from google.colab import files\n","uploaded = files.upload()\n","\n","f=open('chatbot.txt','r',  encoding='utf8', errors = 'ignore')\n","raw=f.read()\n","raw = raw.lower()# converts to lowercase"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BqC8YVkKemk5"},"source":["# **Basic text pre-processing includes:**\n","\n","*   Converting to lowercase, (algorothmn consistency)\n","*   Tokenization\n","*   Removing the Stop words.\n","*   Stemming:  \n","*   Lemmatization:"]},{"cell_type":"markdown","metadata":{"id":"GrP0fxO7lPnu"},"source":["# **Tokenisation**"]},{"cell_type":"code","metadata":{"id":"iteUnJTxlehg"},"source":["sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences \n","word_tokens = nltk.word_tokenize(raw)# converts to list of words"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QOw-Kt3xlrWE"},"source":["# **Preprocessing**\n","We shall now define a function called LemTokens which will take as input the tokens and return normalized tokens."]},{"cell_type":"code","metadata":{"id":"mMF50KjAemLf"},"source":["# Preprocessing\n","lemmer = WordNetLemmatizer()\n","def LemTokens(tokens):\n","    return [lemmer.lemmatize(token) for token in tokens]\n","remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n","def LemNormalize(text):\n","    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Tji99M6l6do"},"source":["# **Keyword matching**\n","Next, we shall define a function for a greeting by the bot i.e if a user’s input is a greeting, the bot shall return a greeting response. \n","ELIZA uses a simple keyword matching for greetings. We will utilize the same concept here."]},{"cell_type":"code","metadata":{"id":"1YCUBbk8e78c"},"source":["GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n","GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n","def greeting(sentence):\n"," \n","    for word in sentence.split():\n","        if word.lower() in GREETING_INPUTS:\n","            return random.choice(GREETING_RESPONSES)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sWSELixQtDsP"},"source":["### **Generating Response**\n","\n","**Bag of Words**\n","\n","After the initial preprocessing phase, we need to transform text into a meaningful vector (or array) of numbers. The bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n","\n","*   A vocabulary of known words.\n","*   A measure of the presence of known words.\n","\n","For example, if our dictionary contains the words {Learning, is, the, not, great}, and we want to vectorize the text “Learning is great”, we would have the following vector: (1, 1, 0, 0, 1).\n","\n","**TF-IDF Approach**\n","\n","A problem with the Bag of Words approach is that highly frequent words start to dominate in the document (e.g. larger score), but may not contain as much “informational content”. Also, it will give more weight to longer documents than shorter documents.\n","\n","One approach is to rescale the frequency of words by how often they appear in all documents so that the scores for frequent words like “the” that are also frequent across all documents are penalized. This approach to scoring is called Term Frequency-Inverse Document Frequency, or TF-IDF for short, where:\n","\n","Term Frequency: is a scoring of the frequency of the word in the current document.\n","\n","TF = (Number of times term t appears in a document)/(Number of terms in the document)\n","Inverse Document Frequency: is a scoring of how rare the word is across documents.\n","\n","IDF = 1+log(N/n), where, N is the number of documents and n is the number of documents a term t has appeared in.\n","\n","**Cosine Similarity**\n","Tf-idf weight is a weight often used in information retrieval and text mining. This weight is a statistical measure used to evaluate how important a word is to a document in a collection or corpus\n","\n","Cosine Similarity (d1, d2) =  Dot product(d1, d2) / ||d1|| * ||d2||\n","where d1,d2 are two non zero vectors.\n","\n","To generate a response from our bot for input questions, the concept of document similarity will be used. \n","\n","We define a function response which searches the user’s utterance for one or more known keywords and returns one of several possible responses. \n","\n","If it doesn’t find the input matching any of the keywords, it returns a response:” I am sorry! I don’t understand you”"]},{"cell_type":"code","metadata":{"id":"d3cinhMDe_Jc"},"source":["def response(user_response):\n","    robo_response=''\n","    sent_tokens.append(user_response)\n","    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n","    tfidf = TfidfVec.fit_transform(sent_tokens)\n","    vals = cosine_similarity(tfidf[-1], tfidf)\n","    idx=vals.argsort()[0][-2]\n","    flat = vals.flatten()\n","    flat.sort()\n","    req_tfidf = flat[-2]\n","    if(req_tfidf==0):\n","        robo_response=robo_response+\"I am sorry! I don't understand you\"\n","        return robo_response\n","    else:\n","        robo_response = robo_response+sent_tokens[idx]\n","        return robo_response"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rk8Av-iTtLQ8"},"source":["Finally, we will feed the lines that we want our bot to say while starting and ending a conversation depending upon user’s input."]},{"cell_type":"code","metadata":{"id":"vW-ZK6frtPpP"},"source":["flag=True\n","print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n","while(flag==True):\n","    user_response = input()\n","    user_response=user_response.lower()\n","    if(user_response!='bye'):\n","        if(user_response=='thanks' or user_response=='thank you' ):\n","            flag=False\n","            print(\"ROBO: You are welcome..\")\n","        else:\n","            if(greeting(user_response)!=None):\n","                print(\"ROBO: \"+greeting(user_response))\n","            else:\n","                print(\"ROBO: \",end=\"\")\n","                print(response(user_response))\n","                sent_tokens.remove(user_response)\n","    else:\n","        flag=False\n","        print(\"ROBO: Bye! take care..\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aVraCAWk487P"},"source":["# **Your Questions**\n","\n","**Question 1**: What is wrong with the Chatbot we created? - please answer at: [Got to](www.menti.com)  Code: 85 12 71 5\n","**Question 2**: Which of the following NLP statements are false? - please answer at: [Got to](www.menti.com)  Code: 85 12 71 5\n"]},{"cell_type":"markdown","metadata":{"id":"DD6hbE6dpdPX"},"source":["# **Other NLP Libraries and Tools** \n","\n","Additional mostly free and open source NLP libraries and APIs:\n","\n","*   Gensim—Similarity detection and topic modeling\n","*   Google Cloud Natural Language API—Cloud-based API for NLP tasks such as named entity recognition, sentiment analysis, parts-of-speech analysis and visualization, determining content categories and more\n","*   Microsoft Linguistic Analysis API\n","*   Bing sentiment analysis—Microsoft’s Bing search engine now uses sentiment in its search results\n","*   PyTorch NLP—Deep learning library for NLP\n","*   Stanford CoreNLP—A Java NLP library, which also provides a Python wrapper. Includes corefererence resolution, which finds all references to the same thing.\n","*   Apache OpenNLP—Another Java-based NLP library for common tasks, including coreference resolution. Python wrappers are available.\n","*   PyNLPl (pineapple)—Python NLP library provides a range of NLP capabilities\n","*   KoNLPy—Korean language NLP\n","*   Latest BERT language models"]},{"cell_type":"markdown","metadata":{"id":"8toP7y5cp_Wt"},"source":["**Machine Learning and Deep Learning Natural Language Applications**\n","\n","*   Answering natural language questions—For example, our publisher Pearson Education, has a partnership with IBM Watson that uses Watson as a virtual tutor. Students ask Watson natural language questions and get answers.\n","*   Summarizing documents—analyzing documents and producing short summaries (abstracts) that can, for example, be included with search results and can help you decide what to read.\n","*   Speech synthesis (speech-to-text), speech recognition (text-to-speech), inter-language text-to-text translation.\n","*   Collaborative filtering—used to implement recommender systems (“if you liked this movie, you might also like…”).\n","*   Text classification—e.g., classifying news articles by categories, such as world news, national news, local news, sports, business, entertainment, etc.\n","*   Topic modeling—finding the topics discussed in documents.\n","*   Sarcasm detection—often used with sentiment analysis.\n","*   Closed captioning—automatically adding text captions to video.\n","*   Speech to sign language and vice versa—to enable a conversation with a hearing-impaired person.\n","*   Lip reader technology—for people who can’t speak, convert lip movement to text or speech to enable conversation.\n"]},{"cell_type":"markdown","metadata":{"id":"-lRtL-9Frd5M"},"source":["# **Natural Language Datasets**\n","\n","*   Wikipedia—some or all of Wikipedia (https://meta.wikimedia.org/wiki/Datasets)\n","*   kaggle.com\n","*   {Big Bad NLP Database - dataset](https://www.kdnuggets.com/2020/02/big-bad-nlp-database.html)\n","*   IMDB (Internet Movie Database)—various movie and TV datasets are available.\n","*   Jeopardy! dataset—200,000+ questions from the Jeopardy! TV show. A milestone in AI occurred in 2011 when IBM Watson famously beat two of the world’s best Jeopardy! players.*   [Natural language processing datasets](https://machinelearningmastery.com/datasets-natural-language-processing/)\n","*  [Amazon Customer Reviews Dataset](https://registry.opendata.aws/amazon-reviews/ over 160+ million product reviews\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Srd4YlVpswE1"},"source":["# **Summary of the session**\n","\n","\n","*   An introduction to NLP\n","*   Use of a range of NLP libraries\n","*   Hands-on practice with a range of NLP tasks - mosty pre-processing for NLP analysis\n","*   An example NLP use case with specific features, models - Chatbot and its limitations\n","*   Some further ML, DL and Dataset information on NLP\n","\n","Thank you!\n"]}]}